{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Introduction\n",
    "\n",
    "### Steps\n",
    "\n",
    "![ml-framework](./res/ml-framework.PNG)\n",
    "\n",
    "\n",
    "### Learning Map\n",
    "\n",
    "![ml-learning-map](./res/ml-learning-map.PNG)\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "Learning from `teacher`.\n",
    "\n",
    "Require a log of training data to find out input/output relationship.\n",
    "\n",
    "We call function output = `label`\n",
    "\n",
    "\n",
    "##### Regression\n",
    "\n",
    "The output of target function $f$ is `scalar`.\n",
    "\n",
    "* Input user action data, find out how much money user will deposit.\n",
    "\n",
    "##### Classfication\n",
    "\n",
    "The output of target function $f$ is a `binary` or `multi-class`.\n",
    "\n",
    "* Is this a cat?\n",
    "\n",
    "* Handwriting recognition.\n",
    "\n",
    "##### Structure Learning\n",
    "\n",
    "The output is beyond classification.\n",
    "\n",
    "* Speech recognition(Output is a sentense).\n",
    "\n",
    "* Face recognition(Tell who this person is).\n",
    "\n",
    "\n",
    "### Semi-Supervised Learning\n",
    "\n",
    "Learning from few labelled data but much more unlabelled data(relating to labelled data).\n",
    "\n",
    "* Distinguish picture is a cat or a dog. In training data, they are all cats and dog, but only few of them are labelled.\n",
    "\n",
    "### Transfer Learning\n",
    "\n",
    "Learning from few labelled data but much more unlabelled data(**NOT** relating to labelled data).\n",
    "\n",
    "* Distinguish picture is a cat or a dog. Training data contains other objects not relating to this task(labelled and unlabelled ones).\n",
    "\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "Input training data, but do not tell what output it should be.\n",
    "\n",
    "* Input a word, and machine tell you meaning of it from reading a lot of documents.\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "Learning from `critics`. Input is good or bad instead of correct answer.\n",
    "\n",
    "* Training machine to play Super Mario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo\n",
    "\n",
    "##### Q: We want to find releationship between `Attack` and `Special Attack` of Water Pokemon.\n",
    "\n",
    "Following code are for preparation, could ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_heatmap(heatmap_df):\n",
    "    \n",
    "    indices = heatmap_df.index.values\n",
    "    columns = list(map(lambda co: co[1], heatmap_df.columns.values))\n",
    "\n",
    "    heatmap = np.array(heatmap_df.values)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    im = ax.imshow(heatmap)\n",
    "    \n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(len(columns)))\n",
    "    ax.set_yticks(np.arange(len(indices)))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax.set_xticklabels(columns)\n",
    "    ax.set_yticklabels(indices)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "\n",
    "    ax.set_title(\"Heatmap\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, show data and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df = pd.read_csv('./res/pokemon.csv', na_values=['NA'])\n",
    "\n",
    "water_pokemon_df = pokemon_df[pokemon_df['Type 1'] == 'Water'].dropna(how='any')\n",
    "\n",
    "print(water_pokemon_df[['Name', 'Type 1', 'Attack', 'Sp. Atk']].head())\n",
    "\n",
    "water_pokemon_df.plot.scatter('Attack', 'Sp. Atk')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Find a set of function\n",
    "Redifine question. \n",
    "\n",
    "let y = `Attack`, x = `Sp. Atk`, find a function \n",
    "\n",
    "$f = ax + b$\n",
    "\n",
    "to match this chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Measure goodness of function\n",
    "\n",
    "In other word, we want to find a function to calculate error of it.\n",
    "\n",
    "That is:\n",
    "\n",
    "We want to find a `loss function` \n",
    "\n",
    "$\n",
    "L(f) = L(a, b) = \\sum_{i=1}^{n} (\\hat{y}^i - (ax^i + b))^2\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Pick best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find best $f^*$ to have minimum loss function\n",
    "\n",
    "That is:\n",
    "\n",
    "$\n",
    "f^* = arg min L(f)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Brute Force Coding Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = water_pokemon_df[['Attack', 'Sp. Atk']].values\n",
    "\n",
    "print(train_data[0:5])\n",
    "\n",
    "step = 10\n",
    "ab_array = [(round(a, 2), round(b, 2)) for a in np.arange(-100, 100, step) for b in np.arange(-100, 100, step)]\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "best_result = None\n",
    "min_total_loss = float('inf')\n",
    "for a, b in ab_array:\n",
    "    total_loss = 0\n",
    "    for (x, y) in train_data:\n",
    "        total_loss += (y - (x*a + b))**2\n",
    "        \n",
    "    if total_loss < min_total_loss:\n",
    "        min_total_loss = total_loss\n",
    "        best_result = [a, b, total_loss]\n",
    "    loss_array.append([a, b, total_loss])\n",
    "\n",
    "loss_array_df = pd.DataFrame(np.array(loss_array))\n",
    "loss_array_df.columns = ['a', 'b', 'loss']\n",
    "\n",
    "print(loss_array_df.head())\n",
    "\n",
    "heatmap_df = pd.pivot_table(loss_array_df, columns=['b'], index=['a'], values=['loss'])\n",
    "\n",
    "print(\"Best result, a = {0}, b = {1}, loss = {2}\".format(best_result[0], best_result[1], best_result[2]))\n",
    "\n",
    "draw_heatmap(heatmap_df)\n",
    "\n",
    "x_array = np.array(list(range(160)))\n",
    "y_array = x_array*best_result[0] + best_result[1]\n",
    "plt.scatter(x=train_data[:, 0], y=train_data[:, 1])\n",
    "plt.plot(x_array, y_array, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above exampe, we might be able to find best function, however, there are some issues.\n",
    "\n",
    "    * Brute force takes time\n",
    "    * It might not cover best function range.\n",
    "    \n",
    "##### Gradient Descent\n",
    "\n",
    "The concept is that if you are not randomly pick a and b, but you move to next point which has less loss function, it could speed up calculation. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = np.arange(-10, 10, 0.1)\n",
    "\n",
    "\n",
    "# y = x^2\n",
    "plt.plot(x_array, x_array**2)\n",
    "plt.annotate('Current argument', arrowprops=dict(facecolor='black'), xy=(7.5, 7.5**2), xytext=(7.5-5, 7.5**2+5))\n",
    "plt.xlabel('a')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Descent Coding example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "l_rate = 0.000001\n",
    "iteration = 200000\n",
    "for i in range(iteration):\n",
    "    \n",
    "    b_grad = 0.0\n",
    "    a_grad = 0.0\n",
    "    for (x, y) in train_data:\n",
    "        b_grad = b_grad - 2.0*(y - b - a*x)*1.0\n",
    "        a_grad = a_grad - 2.0*(y - b - a*x)*x\n",
    "    \n",
    "    b = b - l_rate*b_grad\n",
    "    a = a - l_rate*a_grad\n",
    "    \n",
    "    total_loss = 0\n",
    "    for (x, y) in train_data:\n",
    "        total_loss += (y - (x*a + b))**2\n",
    "        \n",
    "    if i % 10000 == 0:\n",
    "        print(\"Iteration {0}: a = {1}, b = {2}, loss = {3}\".format(i, a, b, total_loss))\n",
    "        \n",
    "x_array = np.array(list(range(160)))\n",
    "y_array = x_array*a + b\n",
    "plt.scatter(x=train_data[:, 0], y=train_data[:, 1])\n",
    "plt.plot(x_array, y_array, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
